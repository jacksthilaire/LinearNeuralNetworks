# -*- coding: utf-8 -*-
"""news_net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1phtdWIsuNvchXVjLfsKHzOknMfCFHZzc
"""

import torch
import torchvision
from torchvision import transforms, datasets
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import pandas as pd
import random
import csv
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize

#########################################################################
# Generic neural net - input an array of [data_tensor, correct_answer]  #
# where data_tensor is a tensor full of doubles (statistical values),   #
# and correct_answer is an integer representing a classification        #
#########################################################################
# Jack St. Hilaire 2020

#########################################################################
print("--- Setup ---")
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Hardware config: Using GPU")
else:
    device = torch.device("cpu")
    print("Hardware config: Using CPU")
#########################################################################

#########################################################################
# load data in from a csv file
def load_data_from_csv(filename):
  data_list = []
  data_file = csv.reader(open(filename), delimiter=',')

  # iterate over each line and read it in column by column
  skip_lines = 1
  for line in data_file:
    if skip_lines > 0:
      skip_lines = skip_lines - 1
    else:
      the_data = []
      the_result = []

      # parse data from strings to ascii, then append to data
      title = line[1] # max 100
      title_len = 100

      body = line[2] # max 500
      body_len = 500

      for ele in range(title_len):
        try:
          the_data.append(float(ord(title[ele])))
        except:
          the_data.append(0.0)

      for ele in range(body_len):
        try:
          the_data.append(float(ord(body[ele])))
        except:
          the_data.append(0.0)

      # parse the result and append
      result_string = line[3]
      if result_string == 'REAL':
        the_result.append(0)
      elif result_string == 'FAKE':
        the_result.append(1)
      else:  
        the_result.append(0)
      
      #create tensors from data and apppend the data point to the list
      train_tensor = torch.tensor(the_data)
      correct = torch.tensor(the_result)
      data_list.append([train_tensor, correct])

  return data_list
#########################################################################

#########################################################################
# set up datasets
data_set = []
data_set = load_data_from_csv("news.csv")

train_set = []
test_set = []

# split into training and testing
print("Data count: ", len(data_set))
data_index = 0
for data_point in data_set:
  if (data_index % 2) == 0:
    train_set.append(data_point)
  else:
    test_set.append(data_point)
  data_index += 1

# shuffle once separated
random.shuffle(train_set)
random.shuffle(test_set)

print("-------------")
#########################################################################

#########################################################################
# neural network class
class Net(nn.Module):

    # initialization of the layers
    def __init__(self):
        super().__init__()

        # 4 fully connected linear layers
        self.fc1 = nn.Linear(600, 32) # input = 1098 float values
        self.fc2 = nn.Linear(32, 32)
        self.fc3 = nn.Linear(32, 32)
        self.fc4 = nn.Linear(32, 2)

    # how data flows through the layers
    # rectified linear activation function

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)

        # after a forward pass return the softmax for the output layer
        return F.log_softmax(x, dim=1)
#########################################################################

#########################################################################
# initialize net and optimizer

net = Net().to(device)
optimizer = optim.Adam(net.parameters(), lr=0.0012)  # learning rate rate default = 0.001
#########################################################################

#########################################################################
# TRAINING
def train_net(epochs):

    # set to train mode and determine epoch count
    net.train() 
    EPOCHS = epochs

    for epoch in range(EPOCHS):
        for data in train_set:
            # data = data and a label
            X, y = data
            X, y = X.to(device), y.to(device)

            # start gradient at 0, which contains loss
            net.zero_grad()
            output = net(X.view(-1, 600).float())
            loss = F.nll_loss(output, y) # calculate loss, using nll because it is an integer 'guess'

            loss.backward()  # back-propagation
            optimizer.step()  # adjust the weights with optimizer
        
        # save the model, print the loss
        model_save_name = 'fakenewsmodel.pt'
        path = F"{model_save_name}" 
        torch.save(net.state_dict(), path)
        print(loss)  # print the loss each epoch

        # also save to drive
        drive_save_name = 'fakenewsmodel.pt'
        drive_path = F"/content/gdrive/My Drive/{drive_save_name}" 
        torch.save(net.state_dict(), drive_path)
#########################################################################

#########################################################################
# TESTING 
def test_net():
    # counters
    correct = 0
    total = 0

    net.eval() # eval mode

    # don't use gradient, don't want to adjust weights when testing

    with torch.no_grad():
      for data in test_set:
        X, y = data
            
        # iterate though 'guesses'
        output = net(X.view(-1, 600).float().to(device))

        for idx, i in enumerate(output):
          # if the class with the highest guess is equal to the y value (actual) at that index
          if torch.argmax(i) == y[idx]:
              correct += 1
          total += 1

    accuracy = round(correct / total, 3) * 100
    # print("Accuracy: %", accuracy)
    return accuracy
#########################################################################

#########################################################################
# attempt to load the model
try:
  model_save_name = 'fakenewsmodel.pt' # input("Enter model name: ")
  path = F"{model_save_name}"
  net.load_state_dict(torch.load(path))
  print("<news_net>$ Model loaded.")
except:
  print("<news_net>$ Unable to load model.")
#########################################################################

#########################################################################
# program loop
while True:
  print("<news_net>$ cmds: {train: tr, test: te, quit: q")

  # user selection of task
  choice = input("<news_net>$")
  if choice == "te":
    accuracy = 0.0
    for i in range(0, 10):
      accuracy += test_net()
    accuracy = accuracy / 10
    print("Accuracy: ", accuracy)
  elif choice == "tr":
      epoch_num = int(input("Enter number of epochs: "))
      train_net(epoch_num)
  else:
      print("<news_net>$ quitting...")
      break
#########################################################################

# JNS Formula for hidden layer size:

# H = # hidden layers
# n = input size
# m = output size
# S = size of each hidden layer

# S = sqrt(m*n) / H

from google.colab import drive
drive.mount('/content/gdrive')